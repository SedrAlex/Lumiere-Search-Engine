{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Comprehensive TF-IDF Evaluation on ANTIQUE Dataset\n",
        "\n",
        "This notebook performs comprehensive evaluation of the TF-IDF model on the ANTIQUE dataset, calculating:\n",
        "- **Mean Average Precision (MAP)**\n",
        "- **Mean Reciprocal Rank (MRR)**\n",
        "- **Precision@100**\n",
        "- **Recall@100**\n",
        "- **F1-Score@100**\n",
        "- **Additional analysis and breakdowns**\n",
        "\n",
        "The evaluation uses the models and data generated from the ANTIQUE TF-IDF Complete Implementation notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "install",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbb01a3-55a4-4719-b7fb-237c3ae53774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install joblib numpy pandas scikit-learn tqdm\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92124b22-ad74-4324-cd9b-a8c2ce06b4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print('‚úì Libraries imported successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading"
      },
      "source": [
        "## 2. Data Loading and Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "load_models",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827300bf-b496-4e91-829b-a3faf7d112e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking required files...\n",
            "‚úì Found: tfidf_vectorizer.joblib\n",
            "‚úì Found: tfidf_matrix.joblib\n",
            "‚úì Found: doc_ids.joblib\n",
            "‚úì Found: queries_df_cleaned.joblib\n",
            "‚úì Found: text_cleaner.joblib\n",
            "‚úì Found: qrels.tsv\n",
            "\n",
            "File verification complete!\n"
          ]
        }
      ],
      "source": [
        "# Define paths\n",
        "BASE_PATH = '/content/drive/MyDrive/tfidf-optimized/'\n",
        "DATA_PATH = '/content/drive/MyDrive/downloads/'\n",
        "\n",
        "# Check if files exist\n",
        "required_files = [\n",
        "    'tfidf_vectorizer.joblib',\n",
        "    'tfidf_matrix.joblib',\n",
        "    'doc_ids.joblib',\n",
        "    'queries_df_cleaned.joblib',\n",
        "    'text_cleaner.joblib'\n",
        "]\n",
        "\n",
        "print('Checking required files...')\n",
        "for file in required_files:\n",
        "    file_path = os.path.join(BASE_PATH, file)\n",
        "    if os.path.exists(file_path):\n",
        "        print(f'‚úì Found: {file}')\n",
        "    else:\n",
        "        print(f'‚úó Missing: {file}')\n",
        "\n",
        "# Load qrels from data directory\n",
        "qrels_path = os.path.join(DATA_PATH, 'qrels.tsv')\n",
        "if os.path.exists(qrels_path):\n",
        "    print(f'‚úì Found: qrels.tsv')\n",
        "else:\n",
        "    print(f'‚úó Missing: qrels.tsv')\n",
        "\n",
        "print('\\nFile verification complete!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "load_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ba5767-5227-4de3-b597-f3ee98a4f576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TF-IDF models and data...\n",
            "‚úì TF-IDF vectorizer loaded\n",
            "‚úì TF-IDF matrix loaded: (402025, 150000)\n",
            "‚úì Document IDs loaded: 402025\n",
            "‚úì Queries loaded: 2426\n",
            "‚úì Qrels loaded: 27422\n",
            "\n",
            "Sample queries:\n",
            "   query_id                                               text  \\\n",
            "0   3097310  What causes severe swelling and pain in the kn...   \n",
            "1   3910705  why don't they put parachutes underneath airpl...   \n",
            "2    237390                how to clean alloy cylinder heads ?   \n",
            "3   2247892                          how do i get them whiter?   \n",
            "4   1078492                    What is Cloud 9 and 7th Heaven?   \n",
            "\n",
            "                                  cleaned_query  \n",
            "0               what caus sever swell pain knee  \n",
            "1  whi not put parachut underneath airplan seat  \n",
            "2                   how clean alloy cylind head  \n",
            "3                                how get whiter  \n",
            "4                             what cloud heaven  \n",
            "\n",
            "Sample qrels:\n",
            "   query_id     doc_id  relevance\n",
            "0   2531329  2531329_0          4\n",
            "1   2531329  2531329_5          4\n",
            "2   2531329  2531329_4          3\n",
            "3   2531329  2531329_7          3\n",
            "4   2531329  2531329_6          3\n"
          ]
        }
      ],
      "source": [
        "# Load models and data\n",
        "print('Loading TF-IDF models and data...')\n",
        "\n",
        "# Define the simple_tokenizer function (required for loading joblib files)\n",
        "def simple_tokenizer(text):\n",
        "    \"\"\"Basic tokenizer: lowercases, removes non-alphanumeric, splits by whitespace.\"\"\"\n",
        "    if text is None:\n",
        "        return []\n",
        "    text = str(text).lower()\n",
        "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
        "    return text.split()\n",
        "\n",
        "# Define the OptimizedAntiqueTextCleaner class (required for loading joblib files)\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "class OptimizedAntiqueTextCleaner:\n",
        "    \"\"\"\n",
        "    An optimized text cleaner for the ANTIQUE dataset, combining steps\n",
        "    for efficiency.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stemmer = PorterStemmer()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        if pd.isna(text) or text is None:\n",
        "            return \"\"\n",
        "        # Lowercasing\n",
        "        text = text.lower()\n",
        "        # Remove non-alphanumeric characters (keeping spaces)\n",
        "        text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "        # Tokenization\n",
        "        tokens = text.split() # Using split as it's generally faster than nltk.word_tokenize for simple cases\n",
        "        # Remove stop words and stem\n",
        "        cleaned_tokens = [\n",
        "            self.stemmer.stem(token) for token in tokens if token not in self.stop_words\n",
        "        ]\n",
        "        # Join tokens back into a string\n",
        "        return \" \".join(cleaned_tokens)\n",
        "\n",
        "\n",
        "# Load TF-IDF components\n",
        "tfidf_vectorizer = joblib.load(os.path.join(BASE_PATH, 'tfidf_vectorizer.joblib'))\n",
        "tfidf_matrix = joblib.load(os.path.join(BASE_PATH, 'tfidf_matrix.joblib'))\n",
        "doc_ids = joblib.load(os.path.join(BASE_PATH, 'doc_ids.joblib'))\n",
        "text_cleaner = joblib.load(os.path.join(BASE_PATH, 'text_cleaner.joblib'))\n",
        "\n",
        "# Load queries\n",
        "queries_df = joblib.load(os.path.join(BASE_PATH, 'queries_df_cleaned.joblib'))\n",
        "\n",
        "# Load qrels\n",
        "qrels_df = pd.read_csv(qrels_path, sep='\\t')\n",
        "\n",
        "print(f'‚úì TF-IDF vectorizer loaded')\n",
        "print(f'‚úì TF-IDF matrix loaded: {tfidf_matrix.shape}')\n",
        "print(f'‚úì Document IDs loaded: {len(doc_ids)}')\n",
        "print(f'‚úì Queries loaded: {len(queries_df)}')\n",
        "print(f'‚úì Qrels loaded: {len(qrels_df)}')\n",
        "\n",
        "# Display sample data\n",
        "print('\\nSample queries:')\n",
        "print(queries_df.head())\n",
        "\n",
        "print('\\nSample qrels:')\n",
        "print(qrels_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing"
      },
      "source": [
        "## 3. Data Preprocessing and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "prepare_evaluation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31b19f9-6a54-416b-8dda-b2571a8cc31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing relevance judgments...\n",
            "Total queries: 2426\n",
            "Queries with relevance judgments: 2426\n",
            "Total relevance judgments: 27422\n",
            "Unique relevant documents: 27422\n",
            "\n",
            "Average relevant docs per query: 11.30\n",
            "Max relevant docs per query: 490\n",
            "Min relevant docs per query: 2\n",
            "\n",
            "Evaluation data prepared successfully!\n"
          ]
        }
      ],
      "source": [
        "# Prepare relevance judgments\n",
        "print('Preparing relevance judgments...')\n",
        "\n",
        "# Create relevance judgments dictionary\n",
        "relevance_judgments = defaultdict(set)\n",
        "for _, row in qrels_df.iterrows():\n",
        "    query_id = row['query_id']\n",
        "    doc_id = row['doc_id']\n",
        "    relevance = row['relevance']\n",
        "\n",
        "    # Consider relevance >= 1 as relevant\n",
        "    if relevance >= 1:\n",
        "        relevance_judgments[query_id].add(doc_id)\n",
        "\n",
        "# Filter queries that have relevance judgments\n",
        "evaluated_queries = set(relevance_judgments.keys())\n",
        "eval_queries = queries_df[queries_df['query_id'].isin(evaluated_queries)].copy()\n",
        "\n",
        "print(f'Total queries: {len(queries_df)}')\n",
        "print(f'Queries with relevance judgments: {len(eval_queries)}')\n",
        "print(f'Total relevance judgments: {len(qrels_df)}')\n",
        "print(f'Unique relevant documents: {len(set(qrels_df[\"doc_id\"].values))}')\n",
        "\n",
        "# Statistics about relevance judgments\n",
        "rel_per_query = [len(relevance_judgments[qid]) for qid in eval_queries['query_id']]\n",
        "print(f'\\nAverage relevant docs per query: {np.mean(rel_per_query):.2f}')\n",
        "print(f'Max relevant docs per query: {np.max(rel_per_query)}')\n",
        "print(f'Min relevant docs per query: {np.min(rel_per_query)}')\n",
        "\n",
        "print('\\nEvaluation data prepared successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "search_functions"
      },
      "source": [
        "## 4. Search Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "define_search",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adec613b-9630-493a-a555-a567c09593f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing search function...\n",
            "Test query: \"what caus sever swell pain knee\"\n",
            "Found 5 results\n",
            "  1. Doc 3133211_0: 0.6473\n",
            "  2. Doc 2606613_8: 0.4549\n",
            "  3. Doc 3241109_2: 0.3869\n",
            "  4. Doc 2606613_3: 0.3757\n",
            "  5. Doc 1574073_3: 0.3743\n",
            "\n",
            "‚úì Search function working correctly!\n"
          ]
        }
      ],
      "source": [
        "# Define search functions\n",
        "def search_documents(query_text, tfidf_vectorizer, tfidf_matrix, doc_ids, top_k=1000):\n",
        "    \"\"\"\n",
        "    Search documents using TF-IDF cosine similarity.\n",
        "\n",
        "    Args:\n",
        "        query_text: Cleaned query text\n",
        "        tfidf_vectorizer: Trained TF-IDF vectorizer\n",
        "        tfidf_matrix: Document-term matrix\n",
        "        doc_ids: List of document IDs\n",
        "        top_k: Number of top documents to return\n",
        "\n",
        "    Returns:\n",
        "        List of (doc_id, score) tuples\n",
        "    \"\"\"\n",
        "    if not query_text or not query_text.strip():\n",
        "        return []\n",
        "\n",
        "    # Transform query to TF-IDF vector\n",
        "    query_vector = tfidf_vectorizer.transform([query_text])\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "\n",
        "    # Get top-k results\n",
        "    if top_k < len(doc_ids):\n",
        "        top_indices = np.argpartition(similarities, -top_k)[-top_k:]\n",
        "        top_indices = top_indices[np.argsort(-similarities[top_indices])]\n",
        "    else:\n",
        "        top_indices = np.argsort(-similarities)\n",
        "\n",
        "    # Return results with scores > 0\n",
        "    results = [(doc_ids[i], similarities[i]) for i in top_indices if similarities[i] > 0]\n",
        "    return results\n",
        "\n",
        "# Test search function\n",
        "print('Testing search function...')\n",
        "test_query = eval_queries.iloc[0]['cleaned_query']\n",
        "test_results = search_documents(test_query, tfidf_vectorizer, tfidf_matrix, doc_ids, top_k=5)\n",
        "print(f'Test query: \"{test_query}\"')\n",
        "print(f'Found {len(test_results)} results')\n",
        "for i, (doc_id, score) in enumerate(test_results):\n",
        "    print(f'  {i+1}. Doc {doc_id}: {score:.4f}')\n",
        "\n",
        "print('\\n‚úì Search function working correctly!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation_metrics"
      },
      "source": [
        "## 5. Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "define_metrics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9941ac5b-a74c-4029-da76-442460e26a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Evaluation metrics defined successfully!\n"
          ]
        }
      ],
      "source": [
        "# Define evaluation metrics\n",
        "def calculate_average_precision(retrieved_docs, relevant_docs):\n",
        "    \"\"\"\n",
        "    Calculate Average Precision (AP) for a single query.\n",
        "\n",
        "    Args:\n",
        "        retrieved_docs: List of retrieved document IDs in ranked order\n",
        "        relevant_docs: Set of relevant document IDs for the query\n",
        "\n",
        "    Returns:\n",
        "        Average Precision score\n",
        "    \"\"\"\n",
        "    if not relevant_docs or len(relevant_docs) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    if not retrieved_docs or len(retrieved_docs) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    hits = 0\n",
        "    sum_precisions = 0.0\n",
        "\n",
        "    for i, doc_id in enumerate(retrieved_docs):\n",
        "        if doc_id in relevant_docs:\n",
        "            hits += 1\n",
        "            precision_at_i = hits / (i + 1)\n",
        "            sum_precisions += precision_at_i\n",
        "\n",
        "    return sum_precisions / len(relevant_docs)\n",
        "\n",
        "def calculate_precision_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Calculate Precision@k.\n",
        "    \"\"\"\n",
        "    if k == 0 or len(retrieved_docs) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    relevant_retrieved = 0\n",
        "    for i, doc_id in enumerate(retrieved_docs[:k]):\n",
        "        if doc_id in relevant_docs:\n",
        "            relevant_retrieved += 1\n",
        "\n",
        "    return relevant_retrieved / min(k, len(retrieved_docs))\n",
        "\n",
        "def calculate_recall_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Calculate Recall@k.\n",
        "    \"\"\"\n",
        "    if len(relevant_docs) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    relevant_retrieved = 0\n",
        "    for i, doc_id in enumerate(retrieved_docs[:k]):\n",
        "        if doc_id in relevant_docs:\n",
        "            relevant_retrieved += 1\n",
        "\n",
        "    return relevant_retrieved / len(relevant_docs)\n",
        "\n",
        "def calculate_reciprocal_rank(retrieved_docs, relevant_docs):\n",
        "    \"\"\"\n",
        "    Calculate Reciprocal Rank for a single query.\n",
        "    \"\"\"\n",
        "    for i, doc_id in enumerate(retrieved_docs):\n",
        "        if doc_id in relevant_docs:\n",
        "            return 1.0 / (i + 1)\n",
        "    return 0.0\n",
        "\n",
        "def calculate_f1_at_k(retrieved_docs, relevant_docs, k):\n",
        "    \"\"\"\n",
        "    Calculate F1-Score@k.\n",
        "    \"\"\"\n",
        "    precision = calculate_precision_at_k(retrieved_docs, relevant_docs, k)\n",
        "    recall = calculate_recall_at_k(retrieved_docs, relevant_docs, k)\n",
        "\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('‚úì Evaluation metrics defined successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_evaluation"
      },
      "source": [
        "## 6. Run Comprehensive Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "comprehensive_evaluation",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d906ae77-911b-4475-a909-d1fce56e9e94"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting comprehensive evaluation...\n",
            "============================================================\n",
            "Evaluating 2426 queries...\n",
            "Progress updates every 50 queries\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|‚ñè         | 50/2426 [00:38<28:46,  1.38it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 50/2426 (2.1%)\n",
            "  Elapsed: 38.1s, Remaining: 1811.7s\n",
            "  Current MAP: 0.0370, Current MRR: 0.1946\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|‚ñç         | 100/2426 [01:11<24:25,  1.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 100/2426 (4.1%)\n",
            "  Elapsed: 71.4s, Remaining: 1661.3s\n",
            "  Current MAP: 0.0474, Current MRR: 0.2142\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|‚ñå         | 150/2426 [01:46<27:26,  1.38it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 150/2426 (6.2%)\n",
            "  Elapsed: 106.0s, Remaining: 1608.7s\n",
            "  Current MAP: 0.0459, Current MRR: 0.2180\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|‚ñä         | 200/2426 [02:23<24:32,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 200/2426 (8.2%)\n",
            "  Elapsed: 143.9s, Remaining: 1602.1s\n",
            "  Current MAP: 0.0447, Current MRR: 0.2093\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|‚ñà         | 250/2426 [03:00<26:58,  1.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 250/2426 (10.3%)\n",
            "  Elapsed: 180.1s, Remaining: 1567.8s\n",
            "  Current MAP: 0.0532, Current MRR: 0.2177\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|‚ñà‚ñè        | 300/2426 [03:34<23:10,  1.53it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 300/2426 (12.4%)\n",
            "  Elapsed: 214.2s, Remaining: 1518.0s\n",
            "  Current MAP: 0.0572, Current MRR: 0.2224\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|‚ñà‚ñç        | 350/2426 [04:07<23:41,  1.46it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 350/2426 (14.4%)\n",
            "  Elapsed: 247.9s, Remaining: 1470.7s\n",
            "  Current MAP: 0.0585, Current MRR: 0.2230\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|‚ñà‚ñã        | 400/2426 [04:40<21:03,  1.60it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 400/2426 (16.5%)\n",
            "  Elapsed: 280.2s, Remaining: 1419.0s\n",
            "  Current MAP: 0.0592, Current MRR: 0.2165\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|‚ñà‚ñä        | 450/2426 [05:13<22:46,  1.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 450/2426 (18.5%)\n",
            "  Elapsed: 313.1s, Remaining: 1375.0s\n",
            "  Current MAP: 0.0633, Current MRR: 0.2292\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|‚ñà‚ñà        | 500/2426 [05:46<20:20,  1.58it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 500/2426 (20.6%)\n",
            "  Elapsed: 346.5s, Remaining: 1334.9s\n",
            "  Current MAP: 0.0630, Current MRR: 0.2240\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|‚ñà‚ñà‚ñé       | 550/2426 [06:19<19:42,  1.59it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 550/2426 (22.7%)\n",
            "  Elapsed: 379.1s, Remaining: 1293.1s\n",
            "  Current MAP: 0.0626, Current MRR: 0.2237\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|‚ñà‚ñà‚ñç       | 600/2426 [06:52<21:18,  1.43it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 600/2426 (24.7%)\n",
            "  Elapsed: 412.5s, Remaining: 1255.2s\n",
            "  Current MAP: 0.0661, Current MRR: 0.2321\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|‚ñà‚ñà‚ñã       | 650/2426 [07:25<18:06,  1.63it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 650/2426 (26.8%)\n",
            "  Elapsed: 445.2s, Remaining: 1216.3s\n",
            "  Current MAP: 0.0650, Current MRR: 0.2315\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|‚ñà‚ñà‚ñâ       | 700/2426 [07:57<19:26,  1.48it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 700/2426 (28.9%)\n",
            "  Elapsed: 477.7s, Remaining: 1178.0s\n",
            "  Current MAP: 0.0643, Current MRR: 0.2299\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|‚ñà‚ñà‚ñà       | 750/2426 [08:31<18:32,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 750/2426 (30.9%)\n",
            "  Elapsed: 511.4s, Remaining: 1142.7s\n",
            "  Current MAP: 0.0620, Current MRR: 0.2260\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|‚ñà‚ñà‚ñà‚ñé      | 800/2426 [09:05<18:13,  1.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 800/2426 (33.0%)\n",
            "  Elapsed: 545.4s, Remaining: 1108.6s\n",
            "  Current MAP: 0.0608, Current MRR: 0.2235\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|‚ñà‚ñà‚ñà‚ñå      | 850/2426 [09:39<16:45,  1.57it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 850/2426 (35.0%)\n",
            "  Elapsed: 579.4s, Remaining: 1074.3s\n",
            "  Current MAP: 0.0606, Current MRR: 0.2240\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|‚ñà‚ñà‚ñà‚ñã      | 900/2426 [10:12<15:43,  1.62it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 900/2426 (37.1%)\n",
            "  Elapsed: 612.2s, Remaining: 1038.0s\n",
            "  Current MAP: 0.0592, Current MRR: 0.2201\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|‚ñà‚ñà‚ñà‚ñâ      | 950/2426 [10:49<17:26,  1.41it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 950/2426 (39.2%)\n",
            "  Elapsed: 649.9s, Remaining: 1009.7s\n",
            "  Current MAP: 0.0584, Current MRR: 0.2210\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 41%|‚ñà‚ñà‚ñà‚ñà      | 1000/2426 [11:24<15:32,  1.53it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1000/2426 (41.2%)\n",
            "  Elapsed: 684.3s, Remaining: 975.8s\n",
            "  Current MAP: 0.0576, Current MRR: 0.2162\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 1050/2426 [12:00<16:21,  1.40it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1050/2426 (43.3%)\n",
            "  Elapsed: 720.2s, Remaining: 943.7s\n",
            "  Current MAP: 0.0565, Current MRR: 0.2134\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 1100/2426 [12:35<14:57,  1.48it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1100/2426 (45.3%)\n",
            "  Elapsed: 755.0s, Remaining: 910.1s\n",
            "  Current MAP: 0.0567, Current MRR: 0.2132\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 1150/2426 [13:09<14:23,  1.48it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1150/2426 (47.4%)\n",
            "  Elapsed: 789.5s, Remaining: 876.0s\n",
            "  Current MAP: 0.0576, Current MRR: 0.2173\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 1200/2426 [13:42<13:40,  1.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1200/2426 (49.5%)\n",
            "  Elapsed: 822.9s, Remaining: 840.7s\n",
            "  Current MAP: 0.0577, Current MRR: 0.2161\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1250/2426 [14:17<12:59,  1.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1250/2426 (51.5%)\n",
            "  Elapsed: 857.2s, Remaining: 806.4s\n",
            "  Current MAP: 0.0573, Current MRR: 0.2152\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1300/2426 [14:50<12:39,  1.48it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: 1300/2426 (53.6%)\n",
            "  Elapsed: 890.8s, Remaining: 771.6s\n",
            "  Current MAP: 0.0565, Current MRR: 0.2130\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1350/2426 [15:25<12:23,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1350/2426 (55.6%)\n",
            "  Elapsed: 925.8s, Remaining: 737.9s\n",
            "  Current MAP: 0.0568, Current MRR: 0.2155\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 1400/2426 [15:59<11:19,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1400/2426 (57.7%)\n",
            "  Elapsed: 960.0s, Remaining: 703.5s\n",
            "  Current MAP: 0.0559, Current MRR: 0.2151\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 1450/2426 [16:34<11:08,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1450/2426 (59.8%)\n",
            "  Elapsed: 994.5s, Remaining: 669.4s\n",
            "  Current MAP: 0.0551, Current MRR: 0.2132\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 1500/2426 [17:08<10:19,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1500/2426 (61.8%)\n",
            "  Elapsed: 1028.9s, Remaining: 635.2s\n",
            "  Current MAP: 0.0548, Current MRR: 0.2131\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 1550/2426 [17:43<09:52,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1550/2426 (63.9%)\n",
            "  Elapsed: 1063.7s, Remaining: 601.2s\n",
            "  Current MAP: 0.0541, Current MRR: 0.2104\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1600/2426 [18:17<09:32,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1600/2426 (66.0%)\n",
            "  Elapsed: 1097.7s, Remaining: 566.7s\n",
            "  Current MAP: 0.0547, Current MRR: 0.2114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 1650/2426 [18:52<08:50,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1650/2426 (68.0%)\n",
            "  Elapsed: 1132.5s, Remaining: 532.6s\n",
            "  Current MAP: 0.0550, Current MRR: 0.2118\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1700/2426 [19:26<08:10,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1700/2426 (70.1%)\n",
            "  Elapsed: 1166.4s, Remaining: 498.1s\n",
            "  Current MAP: 0.0550, Current MRR: 0.2103\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 1750/2426 [20:00<07:26,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1750/2426 (72.1%)\n",
            "  Elapsed: 1200.6s, Remaining: 463.8s\n",
            "  Current MAP: 0.0543, Current MRR: 0.2074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 1800/2426 [20:35<08:23,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1800/2426 (74.2%)\n",
            "  Elapsed: 1235.3s, Remaining: 429.6s\n",
            "  Current MAP: 0.0546, Current MRR: 0.2077\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 1850/2426 [21:15<06:46,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1850/2426 (76.3%)\n",
            "  Elapsed: 1275.1s, Remaining: 397.0s\n",
            "  Current MAP: 0.0548, Current MRR: 0.2100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 1900/2426 [21:51<06:33,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1900/2426 (78.3%)\n",
            "  Elapsed: 1312.0s, Remaining: 363.2s\n",
            "  Current MAP: 0.0546, Current MRR: 0.2086\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 1950/2426 [22:28<06:09,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 1950/2426 (80.4%)\n",
            "  Elapsed: 1348.8s, Remaining: 329.3s\n",
            "  Current MAP: 0.0544, Current MRR: 0.2092\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 2000/2426 [23:05<05:03,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2000/2426 (82.4%)\n",
            "  Elapsed: 1385.1s, Remaining: 295.0s\n",
            "  Current MAP: 0.0545, Current MRR: 0.2100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 2050/2426 [23:42<04:30,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2050/2426 (84.5%)\n",
            "  Elapsed: 1422.1s, Remaining: 260.8s\n",
            "  Current MAP: 0.0545, Current MRR: 0.2102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 2100/2426 [24:17<04:00,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2100/2426 (86.6%)\n",
            "  Elapsed: 1457.8s, Remaining: 226.3s\n",
            "  Current MAP: 0.0541, Current MRR: 0.2094\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 2150/2426 [24:53<03:13,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2150/2426 (88.6%)\n",
            "  Elapsed: 1493.2s, Remaining: 191.7s\n",
            "  Current MAP: 0.0542, Current MRR: 0.2090\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2200/2426 [25:30<02:44,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2200/2426 (90.7%)\n",
            "  Elapsed: 1530.3s, Remaining: 157.2s\n",
            "  Current MAP: 0.0541, Current MRR: 0.2087\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2250/2426 [26:07<02:13,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2250/2426 (92.7%)\n",
            "  Elapsed: 1567.1s, Remaining: 122.6s\n",
            "  Current MAP: 0.0543, Current MRR: 0.2102\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2300/2426 [26:43<01:28,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2300/2426 (94.8%)\n",
            "  Elapsed: 1603.6s, Remaining: 87.8s\n",
            "  Current MAP: 0.0542, Current MRR: 0.2090\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2350/2426 [27:19<00:54,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2350/2426 (96.9%)\n",
            "  Elapsed: 1639.5s, Remaining: 53.0s\n",
            "  Current MAP: 0.0536, Current MRR: 0.2071\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2400/2426 [27:55<00:19,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: 2400/2426 (98.9%)\n",
            "  Elapsed: 1675.5s, Remaining: 18.2s\n",
            "  Current MAP: 0.0532, Current MRR: 0.2059\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2426/2426 [28:14<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation completed in 1694.38 seconds\n",
            "Successfully evaluated 2426 queries\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run comprehensive evaluation\n",
        "print('üöÄ Starting comprehensive evaluation...')\n",
        "print('=' * 60)\n",
        "\n",
        "# Initialize result storage\n",
        "evaluation_results = {\n",
        "    'average_precisions': [],\n",
        "    'reciprocal_ranks': [],\n",
        "    'precision_at_k': {k: [] for k in [1, 5, 10, 20, 50, 100]},\n",
        "    'recall_at_k': {k: [] for k in [1, 5, 10, 20, 50, 100]},\n",
        "    'f1_at_k': {k: [] for k in [1, 5, 10, 20, 50, 100]},\n",
        "    'query_details': []\n",
        "}\n",
        "\n",
        "# Track progress\n",
        "start_time = time.time()\n",
        "processed_queries = 0\n",
        "total_queries = len(eval_queries)\n",
        "\n",
        "print(f'Evaluating {total_queries} queries...')\n",
        "print('Progress updates every 50 queries\\n')\n",
        "\n",
        "# Process each query\n",
        "for idx, (_, query_row) in enumerate(tqdm(eval_queries.iterrows(), total=total_queries)):\n",
        "    query_id = query_row['query_id']\n",
        "    query_text = query_row['text']\n",
        "    cleaned_query = query_row['cleaned_query']\n",
        "\n",
        "    # Get relevant documents for this query\n",
        "    relevant_docs = relevance_judgments[query_id]\n",
        "\n",
        "    if len(relevant_docs) == 0:\n",
        "        continue\n",
        "\n",
        "    # Search using TF-IDF\n",
        "    search_results = search_documents(\n",
        "        cleaned_query,\n",
        "        tfidf_vectorizer,\n",
        "        tfidf_matrix,\n",
        "        doc_ids,\n",
        "        top_k=1000\n",
        "    )\n",
        "\n",
        "    # Extract document IDs from search results\n",
        "    retrieved_docs = [doc_id for doc_id, score in search_results if score > 0]\n",
        "\n",
        "    if len(retrieved_docs) == 0:\n",
        "        continue\n",
        "\n",
        "    # Calculate metrics\n",
        "    # 1. Average Precision\n",
        "    ap = calculate_average_precision(retrieved_docs, relevant_docs)\n",
        "    evaluation_results['average_precisions'].append(ap)\n",
        "\n",
        "    # 2. Reciprocal Rank\n",
        "    rr = calculate_reciprocal_rank(retrieved_docs, relevant_docs)\n",
        "    evaluation_results['reciprocal_ranks'].append(rr)\n",
        "\n",
        "    # 3. Precision, Recall, and F1 at K\n",
        "    for k in evaluation_results['precision_at_k'].keys():\n",
        "        prec_k = calculate_precision_at_k(retrieved_docs, relevant_docs, k)\n",
        "        rec_k = calculate_recall_at_k(retrieved_docs, relevant_docs, k)\n",
        "        f1_k = calculate_f1_at_k(retrieved_docs, relevant_docs, k)\n",
        "\n",
        "        evaluation_results['precision_at_k'][k].append(prec_k)\n",
        "        evaluation_results['recall_at_k'][k].append(rec_k)\n",
        "        evaluation_results['f1_at_k'][k].append(f1_k)\n",
        "\n",
        "    # Store query details\n",
        "    evaluation_results['query_details'].append({\n",
        "        'query_id': query_id,\n",
        "        'query_text': query_text,\n",
        "        'cleaned_query': cleaned_query,\n",
        "        'num_relevant': len(relevant_docs),\n",
        "        'num_retrieved': len(retrieved_docs),\n",
        "        'average_precision': ap,\n",
        "        'reciprocal_rank': rr,\n",
        "        'precision_at_100': calculate_precision_at_k(retrieved_docs, relevant_docs, 100),\n",
        "        'recall_at_100': calculate_recall_at_k(retrieved_docs, relevant_docs, 100),\n",
        "        'f1_at_100': calculate_f1_at_k(retrieved_docs, relevant_docs, 100)\n",
        "    })\n",
        "\n",
        "    processed_queries += 1\n",
        "\n",
        "    # Progress update\n",
        "    if processed_queries % 50 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        avg_time = elapsed / processed_queries\n",
        "        remaining = (total_queries - processed_queries) * avg_time\n",
        "        current_map = np.mean(evaluation_results[\"average_precisions\"]) if evaluation_results[\"average_precisions\"] else 0.0\n",
        "        current_mrr = np.mean(evaluation_results[\"reciprocal_ranks\"]) if evaluation_results[\"reciprocal_ranks\"] else 0.0\n",
        "\n",
        "        print(f'Progress: {processed_queries}/{total_queries} ({processed_queries/total_queries*100:.1f}%)')\n",
        "        print(f'  Elapsed: {elapsed:.1f}s, Remaining: {remaining:.1f}s')\n",
        "        print(f'  Current MAP: {current_map:.4f}, Current MRR: {current_mrr:.4f}')\n",
        "        print()\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f'\\nEvaluation completed in {total_time:.2f} seconds')\n",
        "print(f'Successfully evaluated {processed_queries} queries')\n",
        "print('=' * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results"
      },
      "source": [
        "## 7. Results and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "display_results",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32d2ff8-475b-401d-8a25-86fb2f4edbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "üìä COMPREHENSIVE EVALUATION RESULTS\n",
            "================================================================================\n",
            "üéØ CORE METRICS:\n",
            "   MAP (Mean Average Precision): 0.0533\n",
            "   MRR (Mean Reciprocal Rank): 0.2055\n",
            "   Precision@100: 0.0187\n",
            "   Recall@100: 0.1931\n",
            "   F1-Score@100: 0.0321\n",
            "\n",
            "üéØ TARGET ASSESSMENT:\n",
            "   ‚ùå MAP target not reached: 0.0533 < 0.2\n",
            "   üìà Improvement needed: 0.1467 points\n",
            "\n",
            "üìà PRECISION AT K:\n",
            "   P@  1: 0.1286\n",
            "   P@  5: 0.0856\n",
            "   P@ 10: 0.0664\n",
            "   P@ 20: 0.0487\n",
            "   P@ 50: 0.0291\n",
            "   P@100: 0.0187\n",
            "\n",
            "üìâ RECALL AT K:\n",
            "   R@  1: 0.0152\n",
            "   R@  5: 0.0488\n",
            "   R@ 10: 0.0741\n",
            "   R@ 20: 0.1061\n",
            "   R@ 50: 0.1537\n",
            "   R@100: 0.1931\n",
            "\n",
            "üîÑ F1-SCORE AT K:\n",
            "   F1@  1: 0.0258\n",
            "   F1@  5: 0.0554\n",
            "   F1@ 10: 0.0617\n",
            "   F1@ 20: 0.0595\n",
            "   F1@ 50: 0.0450\n",
            "   F1@100: 0.0321\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Display comprehensive results\n",
        "print('=' * 80)\n",
        "print('üìä COMPREHENSIVE EVALUATION RESULTS')\n",
        "print('=' * 80)\n",
        "\n",
        "# Core metrics\n",
        "map_score = np.mean(evaluation_results['average_precisions'])\n",
        "mrr_score = np.mean(evaluation_results['reciprocal_ranks'])\n",
        "precision_100 = np.mean(evaluation_results['precision_at_k'][100])\n",
        "recall_100 = np.mean(evaluation_results['recall_at_k'][100])\n",
        "f1_100 = np.mean(evaluation_results['f1_at_k'][100])\n",
        "\n",
        "print(f'üéØ CORE METRICS:')\n",
        "print(f'   MAP (Mean Average Precision): {map_score:.4f}')\n",
        "print(f'   MRR (Mean Reciprocal Rank): {mrr_score:.4f}')\n",
        "print(f'   Precision@100: {precision_100:.4f}')\n",
        "print(f'   Recall@100: {recall_100:.4f}')\n",
        "print(f'   F1-Score@100: {f1_100:.4f}')\n",
        "\n",
        "# Target assessment\n",
        "print('\\nüéØ TARGET ASSESSMENT:')\n",
        "target_map = 0.2\n",
        "if map_score >= target_map:\n",
        "    print(f'   ‚úÖ MAP TARGET ACHIEVED! {map_score:.4f} >= {target_map}')\n",
        "else:\n",
        "    print(f'   ‚ùå MAP target not reached: {map_score:.4f} < {target_map}')\n",
        "    print(f'   üìà Improvement needed: {target_map - map_score:.4f} points')\n",
        "\n",
        "# Precision at different cutoffs\n",
        "print('\\nüìà PRECISION AT K:')\n",
        "for k in [1, 5, 10, 20, 50, 100]:\n",
        "    if evaluation_results['precision_at_k'][k]:\n",
        "        prec_k = np.mean(evaluation_results['precision_at_k'][k])\n",
        "        print(f'   P@{k:3d}: {prec_k:.4f}')\n",
        "\n",
        "# Recall at different cutoffs\n",
        "print('\\nüìâ RECALL AT K:')\n",
        "for k in [1, 5, 10, 20, 50, 100]:\n",
        "    if evaluation_results['recall_at_k'][k]:\n",
        "        rec_k = np.mean(evaluation_results['recall_at_k'][k])\n",
        "        print(f'   R@{k:3d}: {rec_k:.4f}')\n",
        "\n",
        "# F1-Score at different cutoffs\n",
        "print('\\nüîÑ F1-SCORE AT K:')\n",
        "for k in [1, 5, 10, 20, 50, 100]:\n",
        "    if evaluation_results['f1_at_k'][k]:\n",
        "        f1_k = np.mean(evaluation_results['f1_at_k'][k])\n",
        "        print(f'   F1@{k:3d}: {f1_k:.4f}')\n",
        "\n",
        "print('\\n' + '=' * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "statistics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7a6c68-9cf4-4e80-bc6f-4b6bd0f2809d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä DETAILED STATISTICS\n",
            "==================================================\n",
            "Queries evaluated: 2426\n",
            "Total queries with judgments: 2426\n",
            "\n",
            "üìà MAP STATISTICS:\n",
            "   Mean: 0.0533\n",
            "   Median: 0.0095\n",
            "   Std Dev: 0.1089\n",
            "   Min: 0.0000\n",
            "   Max: 1.0000\n",
            "\n",
            "üìâ MRR STATISTICS:\n",
            "   Mean: 0.2055\n",
            "   Median: 0.0357\n",
            "   Std Dev: 0.3313\n",
            "   Min: 0.0000\n",
            "   Max: 1.0000\n",
            "\n",
            "üèÜ PERFORMANCE BREAKDOWN:\n",
            "   High Performance (AP >= 0.5): 34 queries (1.4%)\n",
            "   Medium Performance (0.2 <= AP < 0.5): 146 queries (6.0%)\n",
            "   Low Performance (AP < 0.2): 2246 queries (92.6%)\n",
            "   Zero Performance (AP = 0.0): 283 queries (11.7%)\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Additional statistics\n",
        "print('üìä DETAILED STATISTICS')\n",
        "print('=' * 50)\n",
        "\n",
        "print(f'Queries evaluated: {len(evaluation_results[\"average_precisions\"])}')\n",
        "print(f'Total queries with judgments: {len(eval_queries)}')\n",
        "\n",
        "# MAP statistics\n",
        "print('\\nüìà MAP STATISTICS:')\n",
        "print(f'   Mean: {np.mean(evaluation_results[\"average_precisions\"]):.4f}')\n",
        "print(f'   Median: {np.median(evaluation_results[\"average_precisions\"]):.4f}')\n",
        "print(f'   Std Dev: {np.std(evaluation_results[\"average_precisions\"]):.4f}')\n",
        "print(f'   Min: {np.min(evaluation_results[\"average_precisions\"]):.4f}')\n",
        "print(f'   Max: {np.max(evaluation_results[\"average_precisions\"]):.4f}')\n",
        "\n",
        "# MRR statistics\n",
        "print('\\nüìâ MRR STATISTICS:')\n",
        "print(f'   Mean: {np.mean(evaluation_results[\"reciprocal_ranks\"]):.4f}')\n",
        "print(f'   Median: {np.median(evaluation_results[\"reciprocal_ranks\"]):.4f}')\n",
        "print(f'   Std Dev: {np.std(evaluation_results[\"reciprocal_ranks\"]):.4f}')\n",
        "print(f'   Min: {np.min(evaluation_results[\"reciprocal_ranks\"]):.4f}')\n",
        "print(f'   Max: {np.max(evaluation_results[\"reciprocal_ranks\"]):.4f}')\n",
        "\n",
        "# Performance breakdown\n",
        "print('\\nüèÜ PERFORMANCE BREAKDOWN:')\n",
        "high_perf_queries = [ap for ap in evaluation_results['average_precisions'] if ap >= 0.5]\n",
        "med_perf_queries = [ap for ap in evaluation_results['average_precisions'] if 0.2 <= ap < 0.5]\n",
        "low_perf_queries = [ap for ap in evaluation_results['average_precisions'] if ap < 0.2]\n",
        "\n",
        "total_evaluated = len(evaluation_results['average_precisions'])\n",
        "print(f'   High Performance (AP >= 0.5): {len(high_perf_queries)} queries ({len(high_perf_queries)/total_evaluated*100:.1f}%)')\n",
        "print(f'   Medium Performance (0.2 <= AP < 0.5): {len(med_perf_queries)} queries ({len(med_perf_queries)/total_evaluated*100:.1f}%)')\n",
        "print(f'   Low Performance (AP < 0.2): {len(low_perf_queries)} queries ({len(low_perf_queries)/total_evaluated*100:.1f}%)')\n",
        "\n",
        "# Zero performance queries\n",
        "zero_perf_queries = [ap for ap in evaluation_results['average_precisions'] if ap == 0.0]\n",
        "print(f'   Zero Performance (AP = 0.0): {len(zero_perf_queries)} queries ({len(zero_perf_queries)/total_evaluated*100:.1f}%)')\n",
        "\n",
        "print('\\n' + '=' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "top_queries",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cd2c8e-82a5-40eb-e7e2-127caae50df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç QUERY ANALYSIS\n",
            "==================================================\n",
            "üèÜ TOP 5 PERFORMING QUERIES:\n",
            "1. Query ID: 1225605\n",
            "   AP: 1.0000, RR: 1.0000\n",
            "   Text: \"what are cell lines and a monolayer?...\"\n",
            "   Relevant docs: 2, P@100: 0.0200\n",
            "\n",
            "2. Query ID: 1599582\n",
            "   AP: 0.9667, RR: 1.0000\n",
            "   Text: \"What is the difference between a Masala Dosa and a Rawa Dosa?...\"\n",
            "   Relevant docs: 5, P@100: 0.0500\n",
            "\n",
            "3. Query ID: 88316\n",
            "   AP: 0.9306, RR: 1.0000\n",
            "   Text: \"what is the make of Alfa Romeo?...\"\n",
            "   Relevant docs: 6, P@100: 0.0600\n",
            "\n",
            "4. Query ID: 2770978\n",
            "   AP: 0.8822, RR: 1.0000\n",
            "   Text: \"How is Bali as a honeymoon destination as compared to Phuket?...\"\n",
            "   Relevant docs: 8, P@100: 0.0800\n",
            "\n",
            "5. Query ID: 956761\n",
            "   AP: 0.8762, RR: 1.0000\n",
            "   Text: \"what is the difference between a lesson and a lesson plan?...\"\n",
            "   Relevant docs: 5, P@100: 0.0500\n",
            "\n",
            "‚ùå BOTTOM 5 PERFORMING QUERIES:\n",
            "1. Query ID: 2500332\n",
            "   AP: 0.0000, RR: 0.0000\n",
            "   Text: \"how do you change fractions into word form?...\"\n",
            "   Relevant docs: 4, P@100: 0.0000\n",
            "\n",
            "2. Query ID: 3066868\n",
            "   AP: 0.0000, RR: 0.0000\n",
            "   Text: \"What is your favorite snack and why?...\"\n",
            "   Relevant docs: 10, P@100: 0.0000\n",
            "\n",
            "3. Query ID: 3767197\n",
            "   AP: 0.0000, RR: 0.0000\n",
            "   Text: \"How do I change chess set figures in Yahoo Chess ?...\"\n",
            "   Relevant docs: 2, P@100: 0.0000\n",
            "\n",
            "4. Query ID: 2530659\n",
            "   AP: 0.0000, RR: 0.0000\n",
            "   Text: \"how can you tell if you cat is pregnant?...\"\n",
            "   Relevant docs: 3, P@100: 0.0000\n",
            "\n",
            "5. Query ID: 743628\n",
            "   AP: 0.0000, RR: 0.0000\n",
            "   Text: \"why won't a 90' firebird start?...\"\n",
            "   Relevant docs: 5, P@100: 0.0000\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Analyze top and bottom performing queries\n",
        "print('üîç QUERY ANALYSIS')\n",
        "print('=' * 50)\n",
        "\n",
        "# Sort queries by performance\n",
        "query_performance = sorted(evaluation_results['query_details'], key=lambda x: x['average_precision'], reverse=True)\n",
        "\n",
        "# Top 5 performing queries\n",
        "print('üèÜ TOP 5 PERFORMING QUERIES:')\n",
        "for i, query_info in enumerate(query_performance[:5]):\n",
        "    print(f'{i+1}. Query ID: {query_info[\"query_id\"]}')\n",
        "    print(f'   AP: {query_info[\"average_precision\"]:.4f}, RR: {query_info[\"reciprocal_rank\"]:.4f}')\n",
        "    print(f'   Text: \"{query_info[\"query_text\"][:80]}...\"')\n",
        "    print(f'   Relevant docs: {query_info[\"num_relevant\"]}, P@100: {query_info[\"precision_at_100\"]:.4f}')\n",
        "    print()\n",
        "\n",
        "# Bottom 5 performing queries\n",
        "print('‚ùå BOTTOM 5 PERFORMING QUERIES:')\n",
        "for i, query_info in enumerate(query_performance[-5:]):\n",
        "    print(f'{i+1}. Query ID: {query_info[\"query_id\"]}')\n",
        "    print(f'   AP: {query_info[\"average_precision\"]:.4f}, RR: {query_info[\"reciprocal_rank\"]:.4f}')\n",
        "    print(f'   Text: \"{query_info[\"query_text\"][:80]}...\"')\n",
        "    print(f'   Relevant docs: {query_info[\"num_relevant\"]}, P@100: {query_info[\"precision_at_100\"]:.4f}')\n",
        "    print()\n",
        "\n",
        "print('=' * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## 8. Summary and Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_summary"
      },
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print('üèÅ EVALUATION SUMMARY')\n",
        "print('=' * 60)\n",
        "\n",
        "print(f'‚úÖ Successfully evaluated {processed_queries} queries')\n",
        "print(f'‚úÖ Comprehensive metrics calculated')\n",
        "print(f'‚úÖ Performance analysis completed')\n",
        "\n",
        "print('\\nüìã KEY FINDINGS:')\n",
        "print(f'   ‚Ä¢ MAP: {map_score:.4f} (Target: {target_map})')\n",
        "print(f'   ‚Ä¢ MRR: {mrr_score:.4f}')\n",
        "print(f'   ‚Ä¢ Precision@100: {precision_100:.4f}')\n",
        "print(f'   ‚Ä¢ Recall@100: {recall_100:.4f}')\n",
        "print(f'   ‚Ä¢ F1@100: {f1_100:.4f}')\n",
        "\n",
        "if map_score >= target_map:\n",
        "    print('\\nüéâ SUCCESS: MAP target achieved!')\n",
        "    print('   The TF-IDF model meets the performance requirements.')\n",
        "else:\n",
        "    print('\\nüîß IMPROVEMENT OPPORTUNITIES:')\n",
        "    print('   1. Fine-tune TF-IDF parameters (max_df, min_df, ngram_range)')\n",
        "    print('   2. Enhance query preprocessing and expansion')\n",
        "    print('   3. Implement BM25 scoring for better term weighting')\n",
        "    print('   4. Add pseudo-relevance feedback')\n",
        "    print('   5. Consider semantic embeddings (BERT, etc.)')\n",
        "    print('   6. Optimize text cleaning for medical domain')\n",
        "\n",
        "print('\\nüíæ EVALUATION COMPLETE!')\n",
        "print('   All metrics have been calculated and analyzed.')\n",
        "print('   Results are ready for further analysis or reporting.')\n",
        "print('\\n' + '=' * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54c2a539",
        "outputId": "1e0b488b-4315-4761-e418-662575d61e88"
      },
      "source": [
        "# Download NLTK resources if not already downloaded\n",
        "import nltk\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "print('‚úì NLTK resources checked/downloaded.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì NLTK resources checked/downloaded.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}