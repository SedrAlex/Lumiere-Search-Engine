{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# Quora Dataset TF-IDF Implementation with Advanced Text Cleaning\n",
        "\n",
        "This notebook implements TF-IDF vectorization on the Quora dataset with:\n",
        "- **Advanced custom text cleaning optimized for Quora question pairs**\n",
        "- **Custom tokenization with semantic preservation**\n",
        "- **Inverted index construction**\n",
        "- **Model persistence using joblib**\n",
        "- **Evaluation using MAP metric (target: ‚â• 0.3)**\n",
        "\n",
        "## Dataset Structure\n",
        "- Documents: `/content/drive/MyDrive/downloads/docs.csv`\n",
        "- Queries: `/content/drive/MyDrive/downloads/queries.csv`\n",
        "- Relevance judgments: `/content/drive/MyDrive/downloads/qrels.csv`\n",
        "\n",
        "## Key Optimizations for Quora\n",
        "- Question-specific text preprocessing\n",
        "- Preservation of question markers (what, how, why, etc.)\n",
        "- Handling of duplicate question patterns\n",
        "- Optimized n-gram features for question matching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install nltk scikit-learn pandas numpy joblib tqdm\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import joblib\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading"
      },
      "source": [
        "## 2. Data Loading and Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Define file paths\n",
        "DATA_PATH = '/content/drive/MyDrive/downloads/'\n",
        "DOCS_FILE = os.path.join(DATA_PATH, 'docs.csv')\n",
        "QUERIES_FILE = os.path.join(DATA_PATH, 'queries.csv')\n",
        "QRELS_FILE = os.path.join(DATA_PATH, 'qrels.csv')\n",
        "\n",
        "# Verify files exist\n",
        "files_to_check = [DOCS_FILE, QUERIES_FILE, QRELS_FILE]\n",
        "for file_path in files_to_check:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"‚úì Found: {file_path}\")\n",
        "    else:\n",
        "        print(f\"‚úó Missing: {file_path}\")\n",
        "\n",
        "# Load datasets\n",
        "print(\"\\nLoading datasets...\")\n",
        "docs_df = pd.read_csv(DOCS_FILE)\n",
        "queries_df = pd.read_csv(QUERIES_FILE)\n",
        "qrels_df = pd.read_csv(QRELS_FILE)\n",
        "\n",
        "print(f\"Documents: {len(docs_df)} rows\")\n",
        "print(f\"Queries: {len(queries_df)} rows\")\n",
        "print(f\"Qrels: {len(qrels_df)} rows\")\n",
        "\n",
        "# Display sample data\n",
        "print(\"\\nDocument columns:\", docs_df.columns.tolist())\n",
        "print(\"Query columns:\", queries_df.columns.tolist())\n",
        "print(\"Qrels columns:\", qrels_df.columns.tolist())\n",
        "\n",
        "print(\"\\nSample document:\")\n",
        "print(docs_df.head(1))\n",
        "\n",
        "print(\"\\nSample query:\")\n",
        "print(queries_df.head(1))\n",
        "\n",
        "print(\"\\nSample qrel:\")\n",
        "print(qrels_df.head(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "text_cleaning"
      },
      "source": [
        "## 3. Advanced Text Cleaning for Quora Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "text_cleaning_functions"
      },
      "outputs": [],
      "source": [
        "class QuoraTextCleaner:\n",
        "    \"\"\"\n",
        "    Advanced text cleaning class optimized for Quora question pairs\n",
        "    with semantic preservation and question-specific optimizations.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Setup stopwords with exceptions for important question words\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        \n",
        "        # Remove question words and semantic indicators that are crucial for Quora\n",
        "        question_words = {\n",
        "            'what', 'when', 'where', 'why', 'who', 'which', 'how',\n",
        "            'can', 'could', 'would', 'should', 'will', 'shall',\n",
        "            'do', 'does', 'did', 'is', 'are', 'was', 'were',\n",
        "            'not', 'no', 'never', 'none', 'nothing', 'neither',\n",
        "            'more', 'most', 'less', 'least', 'very', 'quite',\n",
        "            'much', 'many', 'few', 'some', 'any', 'all',\n",
        "            'best', 'better', 'good', 'bad', 'right', 'wrong'\n",
        "        }\n",
        "        self.stop_words = self.stop_words - question_words\n",
        "        \n",
        "        # Initialize lemmatizer\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        \n",
        "        # Common contractions for question text\n",
        "        self.contractions = {\n",
        "            \"don't\": \"do not\",\n",
        "            \"won't\": \"will not\",\n",
        "            \"can't\": \"cannot\",\n",
        "            \"n't\": \" not\",\n",
        "            \"'re\": \" are\",\n",
        "            \"'ve\": \" have\",\n",
        "            \"'ll\": \" will\",\n",
        "            \"'d\": \" would\",\n",
        "            \"'m\": \" am\",\n",
        "            \"what's\": \"what is\",\n",
        "            \"that's\": \"that is\",\n",
        "            \"there's\": \"there is\",\n",
        "            \"here's\": \"here is\",\n",
        "            \"where's\": \"where is\",\n",
        "            \"how's\": \"how is\"\n",
        "        }\n",
        "        \n",
        "        # Question patterns that should be normalized\n",
        "        self.question_patterns = {\n",
        "            r'\\bhow do i\\b': 'how to',\n",
        "            r'\\bhow can i\\b': 'how to',\n",
        "            r'\\bhow should i\\b': 'how to',\n",
        "            r'\\bwhat is the best way to\\b': 'how to',\n",
        "            r'\\bwhat are the ways to\\b': 'how to',\n",
        "            r'\\bwhat are some\\b': 'what are',\n",
        "            r'\\bwhat are the\\b': 'what are'\n",
        "        }\n",
        "    \n",
        "    def smart_clean_text(self, text):\n",
        "        \"\"\"\n",
        "        Enhanced text cleaning optimized for Quora questions.\n",
        "        \n",
        "        Args:\n",
        "            text (str): Input text to clean\n",
        "            \n",
        "        Returns:\n",
        "            str: Cleaned text\n",
        "        \"\"\"\n",
        "        if pd.isna(text) or not isinstance(text, str):\n",
        "            return \"\"\n",
        "            \n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        \n",
        "        # Expand contractions\n",
        "        for contraction, expansion in self.contractions.items():\n",
        "            text = text.replace(contraction, expansion)\n",
        "        \n",
        "        # Normalize question patterns\n",
        "        for pattern, replacement in self.question_patterns.items():\n",
        "            text = re.sub(pattern, replacement, text)\n",
        "        \n",
        "        # Remove or normalize specific patterns\n",
        "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' URL ', text)\n",
        "        text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', ' EMAIL ', text)\n",
        "        text = re.sub(r'<.*?>', ' ', text)\n",
        "        \n",
        "        # Handle numbers more intelligently for questions\n",
        "        text = re.sub(r'\\b(19|20)\\d{2}\\b', ' YEAR ', text)  # Years\n",
        "        text = re.sub(r'\\b\\d+\\.\\d+\\b', ' DECIMAL ', text)  # Decimals\n",
        "        text = re.sub(r'\\b\\d+(?:st|nd|rd|th)\\b', ' ORDINAL ', text)  # Ordinals\n",
        "        text = re.sub(r'\\b\\d+\\b', ' NUMBER ', text)  # Other numbers\n",
        "        \n",
        "        # Handle emphasis and punctuation\n",
        "        text = re.sub(r'[!]{2,}', ' EMPHASIS ', text)\n",
        "        text = re.sub(r'[?]{2,}', ' MULTIQUEST ', text)\n",
        "        text = re.sub(r'[.]{3,}', ' ELLIPSIS ', text)\n",
        "        \n",
        "        # Remove special characters but preserve some important ones\n",
        "        text = re.sub(r'[^a-zA-Z0-9\\s\\-\\'_]', ' ', text)\n",
        "        \n",
        "        # Handle hyphenated words carefully (important for compound terms)\n",
        "        text = re.sub(r'\\b(\\w+)-(\\w+)\\b', r'\\1 \\2 \\1\\2', text)  # Keep both forms\n",
        "        \n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    def custom_tokenizer(self, text):\n",
        "        \"\"\"\n",
        "        Custom tokenizer optimized for Quora questions.\n",
        "        \n",
        "        Args:\n",
        "            text (str): Input text\n",
        "            \n",
        "        Returns:\n",
        "            list: List of processed tokens\n",
        "        \"\"\"\n",
        "        # Clean the text first\n",
        "        cleaned_text = self.smart_clean_text(text)\n",
        "        \n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(cleaned_text)\n",
        "        \n",
        "        # Filter and lemmatize\n",
        "        processed_tokens = []\n",
        "        for token in tokens:\n",
        "            # Skip very short tokens or stopwords\n",
        "            if len(token) < 2 or token in self.stop_words:\n",
        "                continue\n",
        "                \n",
        "            # Skip tokens that are just underscores or dashes\n",
        "            if re.match(r'^[_\\-]+$', token):\n",
        "                continue\n",
        "                \n",
        "            # Lemmatize\n",
        "            lemmatized = self.lemmatizer.lemmatize(token)\n",
        "            processed_tokens.append(lemmatized)\n",
        "        \n",
        "        return processed_tokens\n",
        "\n",
        "# Initialize the text cleaner\n",
        "text_cleaner = QuoraTextCleaner()\n",
        "\n",
        "# Test the cleaning function\n",
        "sample_text = \"What's the best way to learn machine learning? How can I improve my programming skills?\"\n",
        "cleaned_sample = text_cleaner.smart_clean_text(sample_text)\n",
        "tokens_sample = text_cleaner.custom_tokenizer(sample_text)\n",
        "\n",
        "print(\"Original text:\", sample_text)\n",
        "print(\"Cleaned text:\", cleaned_sample)\n",
        "print(\"Tokens:\", tokens_sample)\n",
        "print(\"\\nQuora-optimized text cleaning functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_preprocessing"
      },
      "source": [
        "## 4. Data Preprocessing and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preprocess_data"
      },
      "outputs": [],
      "source": [
        "# Preprocess documents\n",
        "print(\"Preprocessing documents...\")\n",
        "\n",
        "# Handle different possible column names for documents\n",
        "doc_text_col = 'text' if 'text' in docs_df.columns else 'question' if 'question' in docs_df.columns else docs_df.columns[1]\n",
        "doc_id_col = 'doc_id' if 'doc_id' in docs_df.columns else 'id' if 'id' in docs_df.columns else docs_df.columns[0]\n",
        "\n",
        "docs_df['cleaned_text'] = docs_df[doc_text_col].apply(text_cleaner.smart_clean_text)\n",
        "docs_df['doc_id'] = docs_df[doc_id_col].astype(str)\n",
        "\n",
        "# Remove empty documents\n",
        "docs_df = docs_df[docs_df['cleaned_text'].str.len() > 0]\n",
        "print(f\"Documents after cleaning: {len(docs_df)}\")\n",
        "\n",
        "# Preprocess queries\n",
        "print(\"Preprocessing queries...\")\n",
        "\n",
        "# Handle different possible column names for queries\n",
        "query_text_col = 'query' if 'query' in queries_df.columns else 'text' if 'text' in queries_df.columns else 'question' if 'question' in queries_df.columns else queries_df.columns[1]\n",
        "query_id_col = 'query_id' if 'query_id' in queries_df.columns else 'id' if 'id' in queries_df.columns else queries_df.columns[0]\n",
        "\n",
        "queries_df['cleaned_query'] = queries_df[query_text_col].apply(text_cleaner.smart_clean_text)\n",
        "queries_df['query_id'] = queries_df[query_id_col].astype(str)\n",
        "\n",
        "# Remove empty queries\n",
        "queries_df = queries_df[queries_df['cleaned_query'].str.len() > 0]\n",
        "print(f\"Queries after cleaning: {len(queries_df)}\")\n",
        "\n",
        "# Prepare qrels\n",
        "qrels_columns = qrels_df.columns.tolist()\n",
        "if 'query_id' not in qrels_columns:\n",
        "    qrels_df['query_id'] = qrels_df[qrels_columns[0]].astype(str)\n",
        "if 'doc_id' not in qrels_columns:\n",
        "    qrels_df['doc_id'] = qrels_df[qrels_columns[1]].astype(str)\n",
        "    \n",
        "qrels_df['query_id'] = qrels_df['query_id'].astype(str)\n",
        "qrels_df['doc_id'] = qrels_df['doc_id'].astype(str)\n",
        "\n",
        "print(\"\\nData preprocessing complete!\")\n",
        "print(f\"Final dataset sizes:\")\n",
        "print(f\"- Documents: {len(docs_df)}\")\n",
        "print(f\"- Queries: {len(queries_df)}\")\n",
        "print(f\"- Qrels: {len(qrels_df)}\")\n",
        "\n",
        "# Display sample of cleaned data\n",
        "print(\"\\nSample cleaned document:\")\n",
        "print(f\"Original: {docs_df.iloc[0][doc_text_col][:200]}...\")\n",
        "print(f\"Cleaned: {docs_df.iloc[0]['cleaned_text'][:200]}...\")\n",
        "\n",
        "print(\"\\nSample cleaned query:\")\n",
        "print(f\"Original: {queries_df.iloc[0][query_text_col]}\")\n",
        "print(f\"Cleaned: {queries_df.iloc[0]['cleaned_query']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfidf_vectorization"
      },
      "source": [
        "## 5. TF-IDF Vectorization with Custom Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_tfidf"
      },
      "outputs": [],
      "source": [
        "# Create TF-IDF vectorizer with custom preprocessing\n",
        "print(\"Creating TF-IDF vectorizer optimized for Quora questions...\")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    preprocessor=None,  # We handle preprocessing ourselves\n",
        "    tokenizer=text_cleaner.custom_tokenizer,  # Use our custom tokenizer\n",
        "    token_pattern=None,  # Disable default tokenization\n",
        "    lowercase=False,  # Already handled in custom tokenizer\n",
        "    stop_words=None,  # Already handled in custom tokenizer\n",
        "    max_features=12000,  # Optimized vocabulary size for questions\n",
        "    min_df=1,  # Keep rare terms (important for specific questions)\n",
        "    max_df=0.85,  # Remove very common terms\n",
        "    ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "    use_idf=True,\n",
        "    smooth_idf=True,\n",
        "    sublinear_tf=True,  # Apply sublinear TF scaling\n",
        "    norm='l2'  # L2 normalization\n",
        ")\n",
        "\n",
        "# Fit and transform documents\n",
        "print(\"Fitting TF-IDF vectorizer on documents...\")\n",
        "document_texts = docs_df['cleaned_text'].tolist()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(document_texts)\n",
        "\n",
        "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
        "print(f\"Number of features: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
        "print(f\"Matrix sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
        "\n",
        "# Display sample features\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(f\"\\nSample features: {feature_names[:20]}\")\n",
        "bigrams = [f for f in feature_names if ' ' in f]\n",
        "print(f\"Sample bigrams: {bigrams[:10]}\")\n",
        "\n",
        "# Show some question-specific terms\n",
        "question_terms = [f for f in feature_names if any(q in f for q in ['what', 'how', 'why', 'where', 'when'])]\n",
        "print(f\"Question-related terms: {question_terms[:15]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inverted_index"
      },
      "source": [
        "## 6. Inverted Index Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "build_inverted_index"
      },
      "outputs": [],
      "source": [
        "def build_inverted_index(tfidf_matrix, feature_names, doc_ids):\n",
        "    \"\"\"\n",
        "    Build inverted index from TF-IDF matrix.\n",
        "    \n",
        "    Args:\n",
        "        tfidf_matrix: Sparse TF-IDF matrix\n",
        "        feature_names: List of feature names\n",
        "        doc_ids: List of document IDs\n",
        "        \n",
        "    Returns:\n",
        "        dict: Inverted index mapping terms to documents and scores\n",
        "    \"\"\"\n",
        "    print(\"Building inverted index...\")\n",
        "    \n",
        "    inverted_index = defaultdict(dict)\n",
        "    \n",
        "    # Convert to COO format for efficient iteration\n",
        "    coo_matrix = tfidf_matrix.tocoo()\n",
        "    \n",
        "    # Build inverted index\n",
        "    for doc_idx, term_idx, score in tqdm(zip(coo_matrix.row, coo_matrix.col, coo_matrix.data), \n",
        "                                          total=coo_matrix.nnz, desc=\"Building index\"):\n",
        "        if score > 0:  # Only include non-zero scores\n",
        "            term = feature_names[term_idx]\n",
        "            doc_id = doc_ids[doc_idx]\n",
        "            inverted_index[term][doc_id] = float(score)\n",
        "    \n",
        "    # Sort documents by score for each term\n",
        "    for term in inverted_index:\n",
        "        inverted_index[term] = dict(sorted(inverted_index[term].items(), \n",
        "                                          key=lambda x: x[1], reverse=True))\n",
        "    \n",
        "    return dict(inverted_index)\n",
        "\n",
        "# Build inverted index\n",
        "doc_ids = docs_df['doc_id'].tolist()\n",
        "inverted_index = build_inverted_index(tfidf_matrix, feature_names, doc_ids)\n",
        "\n",
        "print(f\"\\nInverted index statistics:\")\n",
        "print(f\"Number of terms: {len(inverted_index)}\")\n",
        "print(f\"Average documents per term: {np.mean([len(docs) for docs in inverted_index.values()]):.2f}\")\n",
        "\n",
        "# Show most frequent terms\n",
        "most_frequent_terms = sorted(inverted_index.keys(), key=lambda x: len(inverted_index[x]), reverse=True)[:10]\n",
        "print(f\"Most frequent terms: {most_frequent_terms}\")\n",
        "\n",
        "# Display sample inverted index entries\n",
        "sample_term = list(inverted_index.keys())[0]\n",
        "print(f\"\\nSample inverted index entry for '{sample_term}':\")\n",
        "sample_docs = dict(list(inverted_index[sample_term].items())[:5])\n",
        "print(sample_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_models"
      },
      "source": [
        "## 7. Save Models and Data using Joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_models_joblib"
      },
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/quora_tfidf_models/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Saving models and data...\")\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "vectorizer_path = os.path.join(output_dir, 'tfidf_vectorizer.joblib')\n",
        "joblib.dump(tfidf_vectorizer, vectorizer_path)\n",
        "print(f\"‚úì Saved TF-IDF vectorizer to {vectorizer_path}\")\n",
        "\n",
        "# Save TF-IDF matrix\n",
        "matrix_path = os.path.join(output_dir, 'tfidf_matrix.joblib')\n",
        "joblib.dump(tfidf_matrix, matrix_path)\n",
        "print(f\"‚úì Saved TF-IDF matrix to {matrix_path}\")\n",
        "\n",
        "# Save inverted index\n",
        "index_path = os.path.join(output_dir, 'inverted_index.joblib')\n",
        "joblib.dump(inverted_index, index_path)\n",
        "print(f\"‚úì Saved inverted index to {index_path}\")\n",
        "\n",
        "# Save document mappings\n",
        "doc_mapping = {\n",
        "    'doc_ids': doc_ids,\n",
        "    'docs_df': docs_df,\n",
        "    'queries_df': queries_df,\n",
        "    'qrels_df': qrels_df\n",
        "}\n",
        "mapping_path = os.path.join(output_dir, 'document_mappings.joblib')\n",
        "joblib.dump(doc_mapping, mapping_path)\n",
        "print(f\"‚úì Saved document mappings to {mapping_path}\")\n",
        "\n",
        "# Save text cleaner\n",
        "cleaner_path = os.path.join(output_dir, 'text_cleaner.joblib')\n",
        "joblib.dump(text_cleaner, cleaner_path)\n",
        "print(f\"‚úì Saved text cleaner to {cleaner_path}\")\n",
        "\n",
        "print(f\"\\nAll models saved successfully to {output_dir}\")\n",
        "\n",
        "# Display saved files\n",
        "saved_files = os.listdir(output_dir)\n",
        "print(f\"\\nSaved files:\")\n",
        "for file in saved_files:\n",
        "    file_path = os.path.join(output_dir, file)\n",
        "    file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
        "    print(f\"- {file}: {file_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "search_function"
      },
      "source": [
        "## 8. Search Function Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "implement_search"
      },
      "outputs": [],
      "source": [
        "def search_documents(query, tfidf_vectorizer, tfidf_matrix, doc_ids, top_k=1000):\n",
        "    \"\"\"\n",
        "    Search documents using TF-IDF cosine similarity.\n",
        "    \n",
        "    Args:\n",
        "        query (str): Search query\n",
        "        tfidf_vectorizer: Fitted TF-IDF vectorizer\n",
        "        tfidf_matrix: Document TF-IDF matrix\n",
        "        doc_ids (list): List of document IDs\n",
        "        top_k (int): Number of top results to return\n",
        "        \n",
        "    Returns:\n",
        "        list: List of (doc_id, score) tuples ranked by relevance\n",
        "    \"\"\"\n",
        "    # Transform query using the fitted vectorizer\n",
        "    query_vector = tfidf_vectorizer.transform([query])\n",
        "    \n",
        "    # Calculate cosine similarity\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "    \n",
        "    # Get top-k results\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    \n",
        "    # Create results list\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        if similarities[idx] > 0:  # Only include documents with non-zero similarity\n",
        "            results.append((doc_ids[idx], similarities[idx]))\n",
        "    \n",
        "    return results\n",
        "\n",
        "def search_with_inverted_index(query, inverted_index, tfidf_vectorizer, doc_ids, top_k=1000):\n",
        "    \"\"\"\n",
        "    Search documents using inverted index for faster retrieval.\n",
        "    \n",
        "    Args:\n",
        "        query (str): Search query\n",
        "        inverted_index (dict): Inverted index\n",
        "        tfidf_vectorizer: Fitted TF-IDF vectorizer\n",
        "        doc_ids (list): List of document IDs\n",
        "        top_k (int): Number of top results to return\n",
        "        \n",
        "    Returns:\n",
        "        list: List of (doc_id, score) tuples ranked by relevance\n",
        "    \"\"\"\n",
        "    # Get query terms using the same tokenizer\n",
        "    query_terms = tfidf_vectorizer.build_analyzer()(query)\n",
        "    \n",
        "    # Collect candidate documents\n",
        "    candidate_docs = defaultdict(float)\n",
        "    \n",
        "    for term in query_terms:\n",
        "        if term in inverted_index:\n",
        "            for doc_id, score in inverted_index[term].items():\n",
        "                candidate_docs[doc_id] += score\n",
        "    \n",
        "    # Sort by score and return top-k\n",
        "    sorted_docs = sorted(candidate_docs.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    return sorted_docs[:top_k]\n",
        "\n",
        "# Test search function\n",
        "test_query = \"How to learn programming efficiently?\"\n",
        "print(f\"Testing search with query: '{test_query}'\")\n",
        "\n",
        "# Search using TF-IDF matrix\n",
        "results_tfidf = search_documents(test_query, tfidf_vectorizer, tfidf_matrix, doc_ids, top_k=5)\n",
        "print(f\"\\nTop 5 results (TF-IDF):\")\n",
        "for i, (doc_id, score) in enumerate(results_tfidf, 1):\n",
        "    print(f\"{i}. Doc {doc_id}: {score:.4f}\")\n",
        "\n",
        "# Search using inverted index\n",
        "results_index = search_with_inverted_index(test_query, inverted_index, tfidf_vectorizer, doc_ids, top_k=5)\n",
        "print(f\"\\nTop 5 results (Inverted Index):\")\n",
        "for i, (doc_id, score) in enumerate(results_index, 1):\n",
        "    print(f\"{i}. Doc {doc_id}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nSearch functions implemented successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evaluation"
      },
      "source": [
        "## 9. Evaluation Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluation_functions"
      },
      "outputs": [],
      "source": [
        "def calculate_average_precision(retrieved_docs, relevant_docs):\n",
        "    \"\"\"\n",
        "    Calculate Average Precision for a single query.\n",
        "    \n",
        "    Args:\n",
        "        retrieved_docs (list): List of retrieved document IDs in rank order\n",
        "        relevant_docs (set): Set of relevant document IDs\n",
        "        \n",
        "    Returns:\n",
        "        float: Average Precision score\n",
        "    \"\"\"\n",
        "    if not relevant_docs:\n",
        "        return 0.0\n",
        "    \n",
        "    precision_at_k = []\n",
        "    relevant_retrieved = 0\n",
        "    \n",
        "    for k, doc_id in enumerate(retrieved_docs, 1):\n",
        "        if doc_id in relevant_docs:\n",
        "            relevant_retrieved += 1\n",
        "            precision_at_k.append(relevant_retrieved / k)\n",
        "    \n",
        "    if not precision_at_k:\n",
        "        return 0.0\n",
        "    \n",
        "    return sum(precision_at_k) / len(relevant_docs)\n",
        "\n",
        "def calculate_map(queries_df, qrels_df, search_function, **search_kwargs):\n",
        "    \"\"\"\n",
        "    Calculate Mean Average Precision (MAP) for all queries.\n",
        "    \n",
        "    Args:\n",
        "        queries_df (pd.DataFrame): DataFrame with queries\n",
        "        qrels_df (pd.DataFrame): DataFrame with relevance judgments\n",
        "        search_function (callable): Search function to use\n",
        "        **search_kwargs: Additional arguments for search function\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (MAP score, list of individual AP scores)\n",
        "    \"\"\"\n",
        "    # Group relevance judgments by query\n",
        "    qrels_grouped = qrels_df.groupby('query_id')['doc_id'].apply(set).to_dict()\n",
        "    \n",
        "    ap_scores = []\n",
        "    \n",
        "    print(\"Calculating MAP...\")\n",
        "    \n",
        "    for _, query_row in tqdm(queries_df.iterrows(), total=len(queries_df), desc=\"Evaluating queries\"):\n",
        "        query_id = query_row['query_id']\n",
        "        query_text = query_row['cleaned_query']\n",
        "        \n",
        "        # Get relevant documents for this query\n",
        "        relevant_docs = qrels_grouped.get(query_id, set())\n",
        "        \n",
        "        if not relevant_docs:\n",
        "            continue\n",
        "        \n",
        "        # Search for documents\n",
        "        results = search_function(query_text, **search_kwargs)\n",
        "        \n",
        "        # Extract document IDs from results\n",
        "        retrieved_docs = [doc_id for doc_id, _ in results]\n",
        "        \n",
        "        # Calculate Average Precision\n",
        "        ap = calculate_average_precision(retrieved_docs, relevant_docs)\n",
        "        ap_scores.append(ap)\n",
        "    \n",
        "    # Calculate MAP\n",
        "    map_score = np.mean(ap_scores) if ap_scores else 0.0\n",
        "    \n",
        "    return map_score, ap_scores\n",
        "\n",
        "def evaluate_system(queries_df, qrels_df, tfidf_vectorizer, tfidf_matrix, inverted_index, doc_ids):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation of the TF-IDF system.\n",
        "    \n",
        "    Args:\n",
        "        queries_df (pd.DataFrame): DataFrame with queries\n",
        "        qrels_df (pd.DataFrame): DataFrame with relevance judgments\n",
        "        tfidf_vectorizer: Fitted TF-IDF vectorizer\n",
        "        tfidf_matrix: Document TF-IDF matrix\n",
        "        inverted_index (dict): Inverted index\n",
        "        doc_ids (list): List of document IDs\n",
        "        \n",
        "    Returns:\n",
        "        dict: Evaluation results\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    # Evaluate using TF-IDF matrix search\n",
        "    print(\"Evaluating TF-IDF matrix search...\")\n",
        "    map_tfidf, ap_scores_tfidf = calculate_map(\n",
        "        queries_df, qrels_df, search_documents,\n",
        "        tfidf_vectorizer=tfidf_vectorizer,\n",
        "        tfidf_matrix=tfidf_matrix,\n",
        "        doc_ids=doc_ids,\n",
        "        top_k=1000\n",
        "    )\n",
        "    \n",
        "    results['tfidf_matrix'] = {\n",
        "        'MAP': map_tfidf,\n",
        "        'AP_scores': ap_scores_tfidf,\n",
        "        'num_queries': len(ap_scores_tfidf)\n",
        "    }\n",
        "    \n",
        "    # Evaluate using inverted index search\n",
        "    print(\"Evaluating inverted index search...\")\n",
        "    map_index, ap_scores_index = calculate_map(\n",
        "        queries_df, qrels_df, search_with_inverted_index,\n",
        "        inverted_index=inverted_index,\n",
        "        tfidf_vectorizer=tfidf_vectorizer,\n",
        "        doc_ids=doc_ids,\n",
        "        top_k=1000\n",
        "    )\n",
        "    \n",
        "    results['inverted_index'] = {\n",
        "        'MAP': map_index,\n",
        "        'AP_scores': ap_scores_index,\n",
        "        'num_queries': len(ap_scores_index)\n",
        "    }\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"Evaluation functions implemented successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_evaluation"
      },
      "source": [
        "## 10. Run Comprehensive Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_evaluation_code"
      },
      "outputs": [],
      "source": [
        "# Run comprehensive evaluation\n",
        "print(\"Starting comprehensive evaluation...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "evaluation_results = evaluate_system(\n",
        "    queries_df, qrels_df, tfidf_vectorizer, tfidf_matrix, inverted_index, doc_ids\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for method, results in evaluation_results.items():\n",
        "    print(f\"\\n{method.upper()} SEARCH:\")\n",
        "    print(f\"MAP Score: {results['MAP']:.4f}\")\n",
        "    print(f\"Number of queries evaluated: {results['num_queries']}\")\n",
        "    print(f\"Average Precision scores - Min: {min(results['AP_scores']):.4f}, Max: {max(results['AP_scores']):.4f}\")\n",
        "    print(f\"Standard deviation: {np.std(results['AP_scores']):.4f}\")\n",
        "    \n",
        "    # Check if MAP is above 0.3\n",
        "    if results['MAP'] > 0.3:\n",
        "        print(f\"‚úÖ MAP > 0.3 TARGET ACHIEVED! ({results['MAP']:.4f})\")\n",
        "    else:\n",
        "        print(f\"‚ùå MAP < 0.3 target not met ({results['MAP']:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"PERFORMANCE ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Performance breakdown\n",
        "tfidf_ap_scores = evaluation_results['tfidf_matrix']['AP_scores']\n",
        "index_ap_scores = evaluation_results['inverted_index']['AP_scores']\n",
        "\n",
        "print(f\"\\nDetailed Performance Analysis:\")\n",
        "print(f\"TF-IDF Matrix Search:\")\n",
        "print(f\"  - Queries with AP > 0.5: {sum(1 for ap in tfidf_ap_scores if ap > 0.5)}\")\n",
        "print(f\"  - Queries with AP > 0.3: {sum(1 for ap in tfidf_ap_scores if ap > 0.3)}\")\n",
        "print(f\"  - Queries with AP > 0.1: {sum(1 for ap in tfidf_ap_scores if ap > 0.1)}\")\n",
        "print(f\"  - Queries with AP = 0: {sum(1 for ap in tfidf_ap_scores if ap == 0)}\")\n",
        "\n",
        "print(f\"\\nInverted Index Search:\")\n",
        "print(f\"  - Queries with AP > 0.5: {sum(1 for ap in index_ap_scores if ap > 0.5)}\")\n",
        "print(f\"  - Queries with AP > 0.3: {sum(1 for ap in index_ap_scores if ap > 0.3)}\")\n",
        "print(f\"  - Queries with AP > 0.1: {sum(1 for ap in index_ap_scores if ap > 0.1)}\")\n",
        "print(f\"  - Queries with AP = 0: {sum(1 for ap in index_ap_scores if ap == 0)}\")\n",
        "\n",
        "# Save evaluation results\n",
        "eval_results_path = os.path.join(output_dir, 'evaluation_results.joblib')\n",
        "joblib.dump(evaluation_results, eval_results_path)\n",
        "print(f\"\\n‚úì Evaluation results saved to {eval_results_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"EVALUATION COMPLETE!\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optimization"
      },
      "source": [
        "## 11. Optimization for Better MAP Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "optimization_code"
      },
      "outputs": [],
      "source": [
        "# If MAP is below 0.3, try optimization strategies\n",
        "current_map = evaluation_results['tfidf_matrix']['MAP']\n",
        "\n",
        "print(\"PERFORMANCE OPTIMIZATION\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"\\nCurrent MAP: {current_map:.4f}\")\n",
        "print(f\"Target MAP: 0.3000\")\n",
        "\n",
        "if current_map < 0.3:\n",
        "    print(\"\\nüîß IMPLEMENTING OPTIMIZATIONS...\")\n",
        "    \n",
        "    # Strategy 1: Adjusted TF-IDF parameters\n",
        "    print(\"\\n1. Testing optimized TF-IDF parameters...\")\n",
        "    \n",
        "    optimized_vectorizer = TfidfVectorizer(\n",
        "        preprocessor=None,\n",
        "        tokenizer=text_cleaner.custom_tokenizer,\n",
        "        token_pattern=None,\n",
        "        lowercase=False,\n",
        "        stop_words=None,\n",
        "        max_features=15000,  # Increased vocabulary\n",
        "        min_df=1,  # Keep all terms\n",
        "        max_df=0.8,  # More restrictive on common terms\n",
        "        ngram_range=(1, 3),  # Include trigrams\n",
        "        use_idf=True,\n",
        "        smooth_idf=True,\n",
        "        sublinear_tf=True,\n",
        "        norm='l2'\n",
        "    )\n",
        "    \n",
        "    # Fit optimized vectorizer\n",
        "    optimized_tfidf_matrix = optimized_vectorizer.fit_transform(document_texts)\n",
        "    print(f\"Optimized TF-IDF matrix shape: {optimized_tfidf_matrix.shape}\")\n",
        "    \n",
        "    # Evaluate optimized system\n",
        "    print(\"Evaluating optimized system...\")\n",
        "    optimized_map, optimized_ap_scores = calculate_map(\n",
        "        queries_df, qrels_df, search_documents,\n",
        "        tfidf_vectorizer=optimized_vectorizer,\n",
        "        tfidf_matrix=optimized_tfidf_matrix,\n",
        "        doc_ids=doc_ids,\n",
        "        top_k=1000\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nOptimization Results:\")\n",
        "    print(f\"Original MAP: {current_map:.4f}\")\n",
        "    print(f\"Optimized MAP: {optimized_map:.4f}\")\n",
        "    print(f\"Improvement: {optimized_map - current_map:.4f}\")\n",
        "    \n",
        "    if optimized_map > 0.3:\n",
        "        print(f\"\\nüéâ SUCCESS! MAP > 0.3 TARGET ACHIEVED!\")\n",
        "        \n",
        "        # Save optimized models\n",
        "        optimized_vectorizer_path = os.path.join(output_dir, 'optimized_tfidf_vectorizer.joblib')\n",
        "        optimized_matrix_path = os.path.join(output_dir, 'optimized_tfidf_matrix.joblib')\n",
        "        \n",
        "        joblib.dump(optimized_vectorizer, optimized_vectorizer_path)\n",
        "        joblib.dump(optimized_tfidf_matrix, optimized_matrix_path)\n",
        "        \n",
        "        print(f\"‚úì Saved optimized models to {output_dir}\")\n",
        "        \n",
        "        # Update the main models\n",
        "        tfidf_vectorizer = optimized_vectorizer\n",
        "        tfidf_matrix = optimized_tfidf_matrix\n",
        "        current_map = optimized_map\n",
        "        \n",
        "    elif optimized_map > current_map:\n",
        "        print(f\"\\n‚ö° Improvement achieved but still below target.\")\n",
        "        print(f\"\\nüìù Additional strategies to try:\")\n",
        "        print(f\"   - Query expansion using word similarity\")\n",
        "        print(f\"   - Different text preprocessing approaches\")\n",
        "        print(f\"   - BM25 scoring instead of TF-IDF\")\n",
        "        print(f\"   - Learning-to-rank methods\")\n",
        "        \n",
        "        # Update with improved model\n",
        "        tfidf_vectorizer = optimized_vectorizer\n",
        "        tfidf_matrix = optimized_tfidf_matrix\n",
        "        current_map = optimized_map\n",
        "    \n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è No improvement with parameter optimization.\")\n",
        "        print(f\"Consider more advanced techniques.\")\n",
        "\n",
        "else:\n",
        "    print(f\"\\nüéâ EXCELLENT! MAP > 0.3 TARGET ACHIEVED!\")\n",
        "    print(f\"The system is performing well with current configuration.\")\n",
        "\n",
        "print(f\"\\nFinal MAP Score: {current_map:.4f}\")\n",
        "print(\"\\n\" + \"=\" * 40)\n",
        "print(\"OPTIMIZATION COMPLETE!\")\n",
        "print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sample_queries"
      },
      "source": [
        "## 12. Sample Query Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_sample_queries"
      },
      "outputs": [],
      "source": [
        "# Test with sample queries to demonstrate the system\n",
        "print(\"SAMPLE QUERY TESTING\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Select some sample queries\n",
        "sample_queries = queries_df.head(5)\n",
        "\n",
        "for _, query_row in sample_queries.iterrows():\n",
        "    query_id = query_row['query_id']\n",
        "    original_query = query_row[query_text_col]\n",
        "    cleaned_query = query_row['cleaned_query']\n",
        "    \n",
        "    print(f\"\\nQuery ID: {query_id}\")\n",
        "    print(f\"Original: {original_query}\")\n",
        "    print(f\"Cleaned: {cleaned_query}\")\n",
        "    \n",
        "    # Get search results\n",
        "    results = search_documents(cleaned_query, tfidf_vectorizer, tfidf_matrix, doc_ids, top_k=5)\n",
        "    \n",
        "    # Get relevant documents from qrels\n",
        "    relevant_docs = set(qrels_df[qrels_df['query_id'] == query_id]['doc_id'].astype(str))\n",
        "    \n",
        "    print(f\"Relevant documents: {len(relevant_docs)}\")\n",
        "    print(f\"Top 5 search results:\")\n",
        "    \n",
        "    for i, (doc_id, score) in enumerate(results[:5], 1):\n",
        "        relevance = \"‚úì\" if doc_id in relevant_docs else \"‚úó\"\n",
        "        print(f\"  {i}. Doc {doc_id} ({relevance}): {score:.4f}\")\n",
        "        \n",
        "        # Show snippet of the document\n",
        "        if doc_id in docs_df['doc_id'].values:\n",
        "            doc_text = docs_df[docs_df['doc_id'] == doc_id][doc_text_col].iloc[0]\n",
        "            snippet = doc_text[:200] + \"...\" if len(doc_text) > 200 else doc_text\n",
        "            print(f\"     \\\"{snippet}\\\"\")\n",
        "    \n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nSample query testing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## 13. Final Summary and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_summary"
      },
      "outputs": [],
      "source": [
        "print(\"FINAL SUMMARY - QUORA TF-IDF IMPLEMENTATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nüìä DATASET STATISTICS:\")\n",
        "print(f\"Documents processed: {len(docs_df)}\")\n",
        "print(f\"Queries processed: {len(queries_df)}\")\n",
        "print(f\"Relevance judgments: {len(qrels_df)}\")\n",
        "\n",
        "print(f\"\\nüîß MODEL CONFIGURATION:\")\n",
        "print(f\"TF-IDF Features: {tfidf_matrix.shape[1]}\")\n",
        "print(f\"Matrix sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
        "print(f\"Inverted index terms: {len(inverted_index)}\")\n",
        "print(f\"N-gram range: {tfidf_vectorizer.ngram_range}\")\n",
        "\n",
        "print(f\"\\nüìà PERFORMANCE RESULTS:\")\n",
        "print(f\"Final MAP Score: {current_map:.4f}\")\n",
        "\n",
        "print(f\"\\nüíæ SAVED MODELS:\")\n",
        "saved_files = os.listdir(output_dir)\n",
        "for file in saved_files:\n",
        "    print(f\"- {file}\")\n",
        "\n",
        "print(f\"\\nüéØ TARGET ACHIEVEMENT:\")\n",
        "if current_map >= 0.3:\n",
        "    print(f\"‚úÖ SUCCESS! MAP score: {current_map:.4f} ‚â• 0.3\")\n",
        "    print(f\"üéâ Quora TF-IDF system meets performance requirements!\")\n",
        "else:\n",
        "    print(f\"‚ùå Target not fully met. MAP score: {current_map:.4f} < 0.3\")\n",
        "    print(f\"‚ö° Consider implementing advanced optimization techniques.\")\n",
        "\n",
        "print(f\"\\nüöÄ SYSTEM FEATURES:\")\n",
        "print(f\"‚úì Advanced Quora-specific text cleaning\")\n",
        "print(f\"‚úì Custom tokenization with semantic preservation\")\n",
        "print(f\"‚úì Optimized TF-IDF vectorization\")\n",
        "print(f\"‚úì Efficient inverted index\")\n",
        "print(f\"‚úì Comprehensive MAP evaluation\")\n",
        "print(f\"‚úì Complete model persistence\")\n",
        "\n",
        "print(f\"\\nüìÇ SYSTEM READY FOR USE!\")\n",
        "print(f\"All models saved to: {output_dir}\")\n",
        "print(f\"\\nTo use the system:\")\n",
        "print(f\"1. Load models using joblib.load()\")\n",
        "print(f\"2. Use search_documents() for new queries\")\n",
        "print(f\"3. Inverted index provides faster term-based search\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"QUORA TF-IDF IMPLEMENTATION COMPLETE!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usage_example"
      },
      "source": [
        "## 14. Usage Example for Future Use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usage_example_code"
      },
      "outputs": [],
      "source": [
        "# Example code for loading and using the saved models\n",
        "print(\"USAGE EXAMPLE FOR FUTURE USE\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "example_code = '''\n",
        "# How to load and use the saved Quora TF-IDF models\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load saved models\n",
        "output_dir = '/content/drive/MyDrive/quora_tfidf_models/'\n",
        "\n",
        "tfidf_vectorizer = joblib.load(output_dir + 'tfidf_vectorizer.joblib')\n",
        "tfidf_matrix = joblib.load(output_dir + 'tfidf_matrix.joblib')\n",
        "inverted_index = joblib.load(output_dir + 'inverted_index.joblib')\n",
        "doc_mappings = joblib.load(output_dir + 'document_mappings.joblib')\n",
        "text_cleaner = joblib.load(output_dir + 'text_cleaner.joblib')\n",
        "\n",
        "# Extract document IDs\n",
        "doc_ids = doc_mappings['doc_ids']\n",
        "\n",
        "# Search function for new queries\n",
        "def search_quora_questions(query, top_k=10):\n",
        "    \"\"\"Search for similar Quora questions\"\"\"\n",
        "    # Transform query using the fitted vectorizer\n",
        "    query_vector = tfidf_vectorizer.transform([query])\n",
        "    \n",
        "    # Calculate similarities\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
        "    \n",
        "    # Get top results\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    \n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        if similarities[idx] > 0:\n",
        "            results.append((doc_ids[idx], similarities[idx]))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Example usage\n",
        "query = \"How to learn machine learning effectively?\"\n",
        "results = search_quora_questions(query)\n",
        "print(f\"Top results for '{query}':\")\n",
        "for doc_id, score in results[:5]:\n",
        "    print(f\"Doc {doc_id}: {score:.4f}\")\n",
        "'''\n",
        "\n",
        "print(\"Copy and save this code for future use:\")\n",
        "print(example_code)\n",
        "\n",
        "# Save the example code to a file\n",
        "example_file_path = os.path.join(output_dir, 'quora_usage_example.py')\n",
        "with open(example_file_path, 'w') as f:\n",
        "    f.write(example_code)\n",
        "\n",
        "print(f\"\\n‚úì Usage example saved to: {example_file_path}\")\n",
        "print(\"\\nThis completes the Quora TF-IDF implementation!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
